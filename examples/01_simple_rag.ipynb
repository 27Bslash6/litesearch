{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Simple RAG with Thedu\n",
    "> We will build a simple rag with thedu. Do not be deceived. We are doing a whole bunch of heavylifting under the hood with very little code."
   ],
   "id": "94f1234b99572d4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T22:23:56.803607Z",
     "start_time": "2025-11-06T22:23:56.583785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from thedu import *\n",
    "from fastcore.all import *\n",
    "import re\n",
    "from selectolax.parser import HTMLParser"
   ],
   "id": "3edd79a6c9ca938",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Ingest a PDF document\n",
    "> We will ingest a sample PDF document from Bruegel.\n",
    "> We will read the PDF document using `read_pdf` function from thedu.ingest module.\n",
    "> We will then scrape the urls from the pdf and then recursively get all pdf's off of those links and ingest them as well.'"
   ],
   "id": "bbe74532d19fe55b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T22:23:59.501602Z",
     "start_time": "2025-11-06T22:23:59.499303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@patch\n",
    "def mk_dest(self:Path, add='_1', suffix=None, force=False):\n",
    "    \"\"\"Add a suffix to the file name before the extension.\"\"\"\n",
    "    if not self.exists(): return self\n",
    "    self=self.parent/self.stem + add + ifnone(suffix, self.suffix)\n",
    "    return self.mk_dest(add, suffix, force) if self.exists() and force else self"
   ],
   "id": "c183600c29b58e78",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T22:24:37.400467Z",
     "start_time": "2025-11-06T22:24:37.390139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BruegelDataset:\n",
    "    ''' Dataset for Bruegel PDF documents.'''\n",
    "    URL = 'https://www.bruegel.org/system/files/2024-06/Bruegel_factsheet_2024_0.pdf'\n",
    "    URI_SCHEMA = r'^http://data\\.europa\\.eu/eli/(?P<typedoc>[^/]+)/(?P<year>\\d{4})/(?P<natural_number>\\d+)/(?P<date>\\d{4}-\\d{2}-\\d{2})/(?P<lang>[a-z]{2,3})/pdfa2a$'\n",
    "    def __init__(self, dest:Path=Path('bruegel_dataset')):\n",
    "        self.dest = dest\n",
    "        self.pdfs = self()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_pdf_link(l:str): return l.strip() and (l.lower().endswith('.pdf') or 'pdf' in l.lower())\n",
    "    @staticmethod\n",
    "    def url2name(url: str) -> str | None:\n",
    "        if re.match(BruegelDataset.URI_SCHEMA, url):\n",
    "            m = re.match(BruegelDataset.URI_SCHEMA, url)\n",
    "            return f\"{m['typedoc']}_{m['year']}_{m['natural_number']}_{m['date']}_{m['lang']}.pdf\"\n",
    "        return url.split('/')[-1] if url.split('/')[-1] != '' else url.rstrip('/').split('/')[-1]+'.html'\n",
    "\n",
    "    def _get_meta(self, r):\n",
    "        try:\n",
    "            meta = HTMLParser(r).tags('meta')\n",
    "            nodes = L([dict2obj(m.attributes) for m in meta]).filter(\n",
    "                lambda m: 'about' in m\n",
    "            ).filter(\n",
    "                lambda m: ('property' in m and m['property'].lower() in ['eli:is_embodied_by','eli:title'])\n",
    "            ).filter(\n",
    "                lambda m: ('resource' in m and 'pdfa2a' in m['resource'].lower()) or 'content' in m\n",
    "            ).groupby('about')\n",
    "            for k in nodes: nodes[k] = merge(*nodes[k])\n",
    "            return L([(nodes[n]['resource'], nodes[n]['content']) for n in nodes])\n",
    "        except: pass\n",
    "\n",
    "\n",
    "    def read_link(self, l, dest=None):\n",
    "        try:\n",
    "\t        p = self.save_pdf(l, dest)\n",
    "\t        return p.read_text()\n",
    "        except: return ''\n",
    "\n",
    "    def save_pdf(self, l:str, dest:Path=None) -> Path | None:\n",
    "        try:\n",
    "            if not l : return None\n",
    "            if not dest: dest = self.dest\n",
    "            p = dest / self.url2name(l)\n",
    "            if not (p.exists() and p.stat().st_size > 1024): p = urlsave(l,p)\n",
    "            return p\n",
    "        except Exception as ex: print(ex); return None\n",
    "\n",
    "    def __call__(self) -> L:\n",
    "        '''Make a dataset of documents from a pdf url and all linked pdfs.'''\n",
    "\n",
    "        def get_linked_pdfs(doc, filter=True):\n",
    "            links = doc.map(lambda p: p.links.map(lambda l: l.uri)).concat().unique()\n",
    "            if filter: links = links.filter(self._is_pdf_link)\n",
    "            return links\n",
    "\n",
    "        pth = self.dest / self.url2name(self.URL)\n",
    "        if not pth.exists(): pth = urlsave(self.URL, self.dest / self.url2name(self.URL))\n",
    "        main_doc = read_pdf(pth)\n",
    "        pdf_lp = Path(self.dest / 'pdf_links')\n",
    "        if not pdf_lp.exists():\n",
    "            links = get_linked_pdfs(main_doc, filter=False)\n",
    "            print(f'Found {len(links)} linked pdfs.')\n",
    "            all_c = parallel(self.read_link, links, threadpool=True, dest=self.dest/'links')\n",
    "            pdf_links = parallel(self._get_meta, all_c, threadpool=True).concat().unique()\n",
    "            print(f'Found {len(pdf_links)} external pdf links.')\n",
    "            pdf_lp.mk_write('\\n'.join([f'{l[0]},{l[1]}' for l in pdf_links]))\n",
    "        url2tit = {l.split(',')[0]: l.split(',')[1] for l in pdf_lp.readlines()}\n",
    "        pdf_list = L([l.split(',')[0] for l in pdf_lp.readlines()])\n",
    "        name2url = {self.url2name(l): l for l in pdf_list}\n",
    "        pdf_set = set(pdf_list.map(self.url2name))\n",
    "        downloaded_pdfs = globtastic(self.dest / 'pdfs', file_glob='*.pdf', func=Path).filter(lambda m: m.stat().st_size > 1024).map(lambda p: p.name)\n",
    "        fetch_list = [name2url.get(d) for d in pdf_set.difference(downloaded_pdfs)]\n",
    "        if fetch_list:\n",
    "            print(f'Downloading {len(fetch_list)} new pdfs...')\n",
    "            parallel(self.save_pdf, fetch_list, dest=self.dest/'pdfs')\n",
    "        return globtastic(self.dest / 'pdfs', file_glob='*.pdf', func=Path).map(lambda m: AttrDict(path=m, title=url2tit[name2url[m.name]]))"
   ],
   "id": "fe6fbcae5619ee36",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T22:25:38.199068Z",
     "start_time": "2025-11-06T22:24:38.147523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "B = BruegelDataset()\n",
    "\n"
   ],
   "id": "efb14b2e333b565d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 417 new pdfs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karthik/code/vedicreader/.venv/lib/python3.13/site-packages/pymupdf/extra.py:201: RuntimeWarning: coroutine 'BruegelDataset.__call__' was never awaited\n",
      "  return _extra.JM_make_textpage_dict(tp, page_dict, raw)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from chonkie import RecursiveChunker",
   "id": "fc870ad5bf172bd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chunker = RecursiveChunker()",
   "id": "a41fcdf86b2fe8b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chunks = chunker('\\n'.join(read_pdf(B.pdfs[0].path).map(lambda p: p.text_plain)))",
   "id": "e16f4a5619fb798c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "for c in chunks[:3]: print(c[:500], '\\n---\\n')",
   "id": "b38816e8fe9fe83a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "31c818f42ceb33bc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
